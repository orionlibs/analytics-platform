---
# Source: grafana-cloud-onboarding/charts/alloy-operator/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: test-alloy-operator
  namespace: test-namespace
  labels:
    helm.sh/chart: alloy-operator-0.3.13
    app.kubernetes.io/name: alloy-operator
    app.kubernetes.io/instance: test
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/managed-by: Helm
automountServiceAccountToken: true
---
# Source: grafana-cloud-onboarding/charts/beyla/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: test-beyla
  namespace: test-namespace
  labels:
    helm.sh/chart: beyla-1.10.0
    app.kubernetes.io/name: beyla
    app.kubernetes.io/instance: test
    app.kubernetes.io/version: "2.7.5"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: beyla
    app.kubernetes.io/component: rbac
automountServiceAccountToken: true
---
# Source: grafana-cloud-onboarding/templates/fleet_management_secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: "grafana-cloud-fleet-management-test-grafana-cloud-onboarding"
  namespace: "test-namespace"
type: Opaque
data:
  username: "MTIzNDU2"
  password: "Z2xjX3RoaXNpc215cGFzc3dvcmQ="
---
# Source: grafana-cloud-onboarding/charts/beyla/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: test-beyla
  namespace: test-namespace
  labels:
    helm.sh/chart: beyla-1.10.0
    app.kubernetes.io/name: beyla
    app.kubernetes.io/instance: test
    app.kubernetes.io/version: "2.7.5"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: beyla
    app.kubernetes.io/component: config
data:
  beyla-config.yml: |
    discovery:
      instrument:
        - k8s_namespace: "*"
    attributes:
      kubernetes:
        enable: true
    filter:
      network:
        k8s_dst_owner_name:
          not_match: '{kube*,*jaeger-agent*,*prometheus*,*promtail*,*grafana-agent*}'
        k8s_src_owner_name:
          not_match: '{kube*,*jaeger-agent*,*prometheus*,*promtail*,*grafana-agent*}'
    prometheus_export:
      path: /metrics
      port: 9090
---
# Source: grafana-cloud-onboarding/charts/alloy-operator/templates/rbac/alloy-manager.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: test-alloy-operator-alloy-manager
  labels:
    helm.sh/chart: alloy-operator-0.3.13
    app.kubernetes.io/name: alloy-operator
    app.kubernetes.io/instance: test
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/managed-by: Helm
rules:
  - apiGroups:
      - collectors.grafana.com
    resources:
      - alloys
      - alloys/status
      - alloys/finalizers
    verbs:
      - create
      - delete
      - get
      - list
      - patch
      - update
      - watch
---
# Source: grafana-cloud-onboarding/charts/alloy-operator/templates/rbac/alloy-objects.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: test-alloy-operator
rules:
  # Rules which allow the management of ConfigMaps, ServiceAccounts, and Services.
  - apiGroups: [""]
    resources: ["configmaps", "secrets", "serviceaccounts", "services"]
    verbs: ["*"]
  # Rules which allow the management of DaemonSets, Deployments, and StatefulSets.
  - apiGroups: ["apps"]
    resources: ["daemonsets", "deployments", "statefulsets"]
    verbs: ["*"]
  # Rules which allow the management of Horizontal Pod Autoscalers.
  - apiGroups: ["autoscaling"]
    resources: ["horizontalpodautoscalers"]
    verbs: ["*"]
  # Rules which allow the management of Ingresses and NetworkPolicies.
  - apiGroups: ["networking.k8s.io"]
    resources: ["ingresses", "networkpolicies"]
    verbs: ["*"]
  # Rules which allow the management of PodDisruptionBudgets.
  - apiGroups: ["policy"]
    resources: ["poddisruptionbudgets"]
    verbs: ["*"]
  # Rules which allow the management of ClusterRoles, ClusterRoleBindings, Roles, and RoleBindings.
  - apiGroups: ["rbac.authorization.k8s.io"]
    resources: ["clusterroles", "clusterrolebindings", "roles", "rolebindings"]
    verbs: ["*"]
---
# Source: grafana-cloud-onboarding/charts/beyla/templates/cluster-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: test-beyla
  labels:
    helm.sh/chart: beyla-1.10.0
    app.kubernetes.io/name: beyla
    app.kubernetes.io/instance: test
    app.kubernetes.io/version: "2.7.5"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: beyla
    app.kubernetes.io/component: rbac
rules:
  - apiGroups: [ "apps" ]
    resources: [ "replicasets" ]
    verbs: [ "list", "watch" ]
  - apiGroups: [ "" ]
    resources: [ "pods", "services", "nodes" ]
    verbs: [ "list", "watch", "get" ]
---
# Source: grafana-cloud-onboarding/charts/alloy-operator/templates/rbac/alloy-manager.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: test-alloy-operator-alloy-manager
  labels:
    helm.sh/chart: alloy-operator-0.3.13
    app.kubernetes.io/name: alloy-operator
    app.kubernetes.io/instance: test
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: test-alloy-operator-alloy-manager
subjects:
  - kind: ServiceAccount
    name: test-alloy-operator
    namespace: test-namespace
---
# Source: grafana-cloud-onboarding/charts/alloy-operator/templates/rbac/alloy-objects.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: test-alloy-operator
  labels:
    helm.sh/chart: alloy-operator-0.3.13
    app.kubernetes.io/name: alloy-operator
    app.kubernetes.io/instance: test
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: test-alloy-operator
subjects:
  - kind: ServiceAccount
    name: test-alloy-operator
    namespace: test-namespace
---
# Source: grafana-cloud-onboarding/charts/beyla/templates/cluster-role-binding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: test-beyla
  labels:
    helm.sh/chart: beyla-1.10.0
    app.kubernetes.io/name: beyla
    app.kubernetes.io/instance: test
    app.kubernetes.io/version: "2.7.5"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: beyla
    app.kubernetes.io/component: rbac
subjects:
  - kind: ServiceAccount
    name: test-beyla
    namespace: test-namespace
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: test-beyla
---
# Source: grafana-cloud-onboarding/charts/alloy-operator/templates/rbac/leader-election.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: test-alloy-operator-leader-election-role
  namespace: test-namespace
  labels:
    helm.sh/chart: alloy-operator-0.3.13
    app.kubernetes.io/name: alloy-operator
    app.kubernetes.io/instance: test
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/managed-by: Helm
rules:
  - apiGroups:
      - ""
    resources:
      - configmaps
    verbs:
      - get
      - list
      - watch
      - create
      - update
      - patch
      - delete
  - apiGroups:
      - coordination.k8s.io
    resources:
      - leases
    verbs:
      - get
      - list
      - watch
      - create
      - update
      - patch
      - delete
  - apiGroups:
      - ""
    resources:
      - events
    verbs:
      - create
      - patch
---
# Source: grafana-cloud-onboarding/charts/alloy-operator/templates/rbac/leader-election.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: test-alloy-operator-leader-election-rolebinding
  namespace: test-namespace
  labels:
    helm.sh/chart: alloy-operator-0.3.13
    app.kubernetes.io/name: alloy-operator
    app.kubernetes.io/instance: test
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: test-alloy-operator-leader-election-role
subjects:
  - kind: ServiceAccount
    name: test-alloy-operator
    namespace: test-namespace
---
# Source: grafana-cloud-onboarding/charts/alloy-operator/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: test-alloy-operator
  namespace: test-namespace
  labels:
    helm.sh/chart: alloy-operator-0.3.13
    app.kubernetes.io/name: alloy-operator
    app.kubernetes.io/instance: test
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 8081
      targetPort: http
      protocol: TCP
    - name: metrics
      port: 8082
      targetPort: metrics
      protocol: TCP
  selector:
    app.kubernetes.io/name: alloy-operator
    app.kubernetes.io/instance: test
---
# Source: grafana-cloud-onboarding/charts/beyla/templates/cache-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: beyla-k8s-cache
  namespace: test-namespace
  labels:
    helm.sh/chart: beyla-1.10.0
    app.kubernetes.io/name: beyla-k8s-cache
    app.kubernetes.io/instance: test
    app.kubernetes.io/version: "2.7.5"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: beyla
    app.kubernetes.io/component: networking
spec:
  ports:
    - port: 50055
      protocol: TCP
      targetPort: grpc
      name: grpc
  selector:
    app.kubernetes.io/name: beyla-k8s-cache
---
# Source: grafana-cloud-onboarding/charts/alloy-operator/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: test-alloy-operator
  namespace: test-namespace
  labels:
    helm.sh/chart: alloy-operator-0.3.13
    app.kubernetes.io/name: alloy-operator
    app.kubernetes.io/instance: test
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: alloy-operator
      app.kubernetes.io/instance: test
  template:
    metadata:
      labels:
        helm.sh/chart: alloy-operator-0.3.13
        app.kubernetes.io/name: alloy-operator
        app.kubernetes.io/instance: test
        app.kubernetes.io/version: "1.4.0"
        app.kubernetes.io/managed-by: Helm
    spec:
      serviceAccountName: test-alloy-operator
      securityContext:
        fsGroup: 1000
        runAsGroup: 1000
        runAsNonRoot: true
        runAsUser: 1000
        seccompProfile:
          type: RuntimeDefault
      containers:
        - name: alloy-operator
          image: "ghcr.io/grafana/alloy-operator:1.4.0"
          imagePullPolicy: IfNotPresent
          args:
            - --health-probe-bind-address=:8081
            - --metrics-bind-address=:8082
            - --leader-elect
            - --leader-election-id=test-alloy-operator

          ports:
            - name: http
              containerPort: 8081
              protocol: TCP
            - name: metrics
              containerPort: 8082
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /healthz
              port: 8081
            initialDelaySeconds: 15
            periodSeconds: 20
          readinessProbe:
            httpGet:
              path: /readyz
              port: 8081
            initialDelaySeconds: 5
            periodSeconds: 10
          resources:
            limits: {}
            requests: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
      nodeSelector:
        kubernetes.io/os: linux
---
# Source: grafana-cloud-onboarding/charts/beyla/templates/cache-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: beyla-k8s-cache
  namespace: test-namespace
  labels:
    helm.sh/chart: beyla-1.10.0
    app.kubernetes.io/name: beyla-k8s-cache
    app.kubernetes.io/instance: test
    app.kubernetes.io/version: "2.7.5"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: beyla
    app.kubernetes.io/component: workload
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: beyla-k8s-cache
  template:
    metadata:
      labels:
        helm.sh/chart: beyla-1.10.0
        app.kubernetes.io/name: beyla-k8s-cache
        app.kubernetes.io/instance: test
        app.kubernetes.io/version: "2.7.5"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/part-of: beyla
    spec:
      serviceAccountName: test-beyla
      containers:
        - name: beyla-cache
          image: docker.io/grafana/beyla-k8s-cache:2
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 50055
              protocol: TCP
              name: grpc
          resources:
            limits:
              cpu: "3.0"
              memory: 2Gi
            requests:
              cpu: "0.1"
              memory: 256Mi
          env:
            - name: BEYLA_K8S_CACHE_PORT
              value: "50055"
---
# Source: grafana-cloud-onboarding/templates/alloy.yaml
apiVersion: collectors.grafana.com/v1alpha1
kind: Alloy
metadata:
  name: test-alloy-daemon
  namespace: test-namespace
spec: 
  alloy:
    clustering:
      enabled: false
      name: ""
      portName: http
    configMap:
      content: |-
        remote.kubernetes.secret "grafana_cloud_fleet_management" {
          name      = "grafana-cloud-fleet-management-test-grafana-cloud-onboarding"
          namespace = "test-namespace"
        }
        remotecfg {
          id = sys.env("GCLOUD_FM_COLLECTOR_ID")
          url = "https://fleet.grafana.com"
          basic_auth {
            username = convert.nonsensitive(remote.kubernetes.secret.grafana_cloud_fleet_management.data["username"])
            password = remote.kubernetes.secret.grafana_cloud_fleet_management.data["password"]
          }
          poll_frequency = "30s"
          attributes = {
            "cluster" = "alloy-example",
            "namespace" = "test-namespace",
            "platform" = "kubernetes",
            "release" = "test",
            "source" = "grafana-cloud-onboarding",
            "sourceVersion" = "0.4.0",
            "workloadName" = "alloy-daemon",
            "workloadType" = "daemonset",
          }
        }
        logging {
          level = "info"
        }
        livedebugging {
          enabled = true
        }
      create: true
      key: null
      name: null
    enableReporting: true
    envFrom: []
    extraArgs: []
    extraEnv:
    - name: CLUSTER_NAME
      value: alloy-example
    - name: GCLOUD_RW_API_KEY
      valueFrom:
        secretKeyRef:
          key: password
          name: grafana-cloud-fleet-management-test-grafana-cloud-onboarding
          namespace: test-namespace
    - name: NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: GCLOUD_FM_COLLECTOR_ID
      value: alloy-$(CLUSTER_NAME)-$(NAMESPACE)-$(POD_NAME)
    extraPorts: []
    hostAliases: []
    lifecycle: {}
    listenAddr: 0.0.0.0
    listenPort: 12345
    listenScheme: HTTP
    livenessProbe: {}
    mounts:
      dockercontainers: false
      extra:
      - mountPath: /var/lib/alloy
        name: alloy-storage
        readOnly: false
      varlog: true
    resources: {}
    securityContext:
      privileged: true
    stabilityLevel: public-preview
    storagePath: /var/lib/alloy
    uiPathPrefix: /
  configReloader:
    customArgs: []
    enabled: true
    image:
      digest: ""
      registry: quay.io
      repository: prometheus-operator/prometheus-config-reloader
      tag: v0.81.0
    resources:
      requests:
        cpu: 10m
        memory: 50Mi
    securityContext: {}
  controller:
    affinity: {}
    autoscaling:
      enabled: false
      horizontal:
        enabled: false
        maxReplicas: 5
        minReplicas: 1
        scaleDown:
          policies: []
          selectPolicy: Max
          stabilizationWindowSeconds: 300
        scaleUp:
          policies: []
          selectPolicy: Max
          stabilizationWindowSeconds: 0
        targetCPUUtilizationPercentage: 0
        targetMemoryUtilizationPercentage: 80
      maxReplicas: 5
      minReplicas: 1
      scaleDown:
        policies: []
        selectPolicy: Max
        stabilizationWindowSeconds: 300
      scaleUp:
        policies: []
        selectPolicy: Max
        stabilizationWindowSeconds: 0
      targetCPUUtilizationPercentage: 0
      targetMemoryUtilizationPercentage: 80
      vertical:
        enabled: false
        recommenders: []
        resourcePolicy:
          containerPolicies:
          - containerName: alloy
            controlledResources:
            - cpu
            - memory
            controlledValues: RequestsAndLimits
            maxAllowed: {}
            minAllowed: {}
        updatePolicy: null
    dnsPolicy: ClusterFirstWithHostNet
    enableStatefulSetAutoDeletePVC: false
    extraAnnotations: {}
    extraContainers: []
    hostNetwork: true
    hostPID: true
    initContainers: []
    nodeSelector: {}
    parallelRollout: true
    podAnnotations: {}
    podDisruptionBudget:
      enabled: false
      maxUnavailable: null
      minAvailable: null
    podLabels: {}
    priorityClassName: ""
    replicas: 1
    terminationGracePeriodSeconds: null
    tolerations: []
    topologySpreadConstraints: []
    type: daemonset
    updateStrategy: {}
    volumeClaimTemplates: []
    volumes:
      extra:
      - hostPath:
          path: /var/lib/alloy
          type: DirectoryOrCreate
        name: alloy-storage
  crds:
    create: false
  extraObjects: []
  global:
    image:
      pullSecrets: []
      registry: ""
    podSecurityContext: {}
  image:
    digest: null
    pullPolicy: IfNotPresent
    pullSecrets: []
    registry: docker.io
    repository: grafana/alloy
    tag: null
  ingress:
    annotations: {}
    enabled: false
    extraPaths: []
    faroPort: 12347
    hosts:
    - chart-example.local
    labels: {}
    path: /
    pathType: Prefix
    tls: []
  nameOverride: alloy-daemon
  rbac:
    create: true
  service:
    annotations: {}
    clusterIP: ""
    enabled: true
    internalTrafficPolicy: Cluster
    nodePort: 31128
    type: ClusterIP
  serviceAccount:
    additionalLabels: {}
    annotations: {}
    automountServiceAccountToken: true
    create: true
    name: null
  serviceMonitor:
    additionalLabels: {}
    enabled: false
    interval: ""
    metricRelabelings: []
    relabelings: []
    tlsConfig: {}
---
# Source: grafana-cloud-onboarding/templates/hooks/post-install_add-finalizer.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: test-grafana-cloud-onboarding-add-finalizer
  namespace: test-namespace
  annotations:
    "helm.sh/hook": post-install,post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
    "helm.sh/hook-weight": "5"
---
# Source: grafana-cloud-onboarding/templates/hooks/pre-delete_remove-alloy-and-finalizer.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: test-grafana-cloud-onboarding-remove-alloy-and-finalizer
  namespace: test-namespace
  annotations:
    helm.sh/hook: pre-delete
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
---
# Source: grafana-cloud-onboarding/templates/hooks/post-install_add-finalizer.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: test-grafana-cloud-onboarding-add-finalizer
  namespace: test-namespace
  annotations:
    "helm.sh/hook": post-install,post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
    "helm.sh/hook-weight": "5"
rules:
  - apiGroups: ["apps"]
    resources: ["deployments"]
    verbs: ["get", "list", "watch", "patch"]
---
# Source: grafana-cloud-onboarding/templates/hooks/pre-delete_remove-alloy-and-finalizer.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: test-grafana-cloud-onboarding-remove-alloy-and-finalizer
  namespace: test-namespace
  annotations:
    helm.sh/hook: pre-delete
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
rules:
  - apiGroups: ["apps"]
    resources: ["deployments"]
    verbs: ["get", "list", "watch", "patch"]
  - apiGroups: ["collectors.grafana.com"]
    resources: ["alloys"]
    verbs: ["get", "list", "watch", "delete"]
---
# Source: grafana-cloud-onboarding/templates/hooks/post-install_add-finalizer.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: test-grafana-cloud-onboarding-add-finalizer
  namespace: test-namespace
  annotations:
    "helm.sh/hook": post-install,post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
    "helm.sh/hook-weight": "5"
subjects:
  - kind: ServiceAccount
    name: test-grafana-cloud-onboarding-add-finalizer
    namespace: test-namespace
roleRef:
  kind: Role
  name: test-grafana-cloud-onboarding-add-finalizer
  apiGroup: rbac.authorization.k8s.io
---
# Source: grafana-cloud-onboarding/templates/hooks/pre-delete_remove-alloy-and-finalizer.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: test-grafana-cloud-onboarding-remove-alloy-and-finalizer
  namespace: test-namespace
  annotations:
    helm.sh/hook: pre-delete
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
subjects:
  - kind: ServiceAccount
    name: test-grafana-cloud-onboarding-remove-alloy-and-finalizer
    namespace: test-namespace
roleRef:
  kind: Role
  name: test-grafana-cloud-onboarding-remove-alloy-and-finalizer
  apiGroup: rbac.authorization.k8s.io
---
# Source: grafana-cloud-onboarding/templates/hooks/post-install_add-finalizer.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: test-grafana-cloud-onboarding-add-finalizer
  namespace: test-namespace
  labels:
    app.kubernetes.io/name: test-grafana-cloud-onboarding-add-finalizer
    app.kubernetes.io/instance: test
    helm.sh/chart: grafana-cloud-onboarding-0.4.0
  annotations:
    helm.sh/hook: post-install,post-upgrade
    helm.sh/hook-weight: "15"
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
spec:
  ttlSecondsAfterFinished: 300
  backoffLimit: 3
  template:
    metadata:
      name: test-grafana-cloud-onboarding-add-finalizer
      labels:
        app.kubernetes.io/name: test-grafana-cloud-onboarding
        app.kubernetes.io/instance: test
        linkerd.io/inject: disabled
        sidecar.istio.io/inject: "false"
    spec:
      restartPolicy: Never
      nodeSelector:
        kubernetes.io/os: linux
      serviceAccountName: test-grafana-cloud-onboarding-add-finalizer
      containers:
        - name: add-finalizers
          image: "ghcr.io/grafana/helm-chart-toolbox-kubectl:0.1.1"
          imagePullPolicy: IfNotPresent
          command:
            - /bin/bash
            - -ce
            - |
              kubectl patch \
                --namespace=test-namespace \
                --patch='{"metadata":{"finalizers":["k8s.grafana.com/finalizer"]}}' \
                deployment/test-alloy-operator
          securityContext:
            runAsNonRoot: true
            runAsUser: 4242
            allowPrivilegeEscalation: false
            capabilities:
              drop: ["ALL"]
            readOnlyRootFilesystem: true
            seccompProfile:
              type: RuntimeDefault
---
# Source: grafana-cloud-onboarding/templates/hooks/pre-delete_remove-alloy-and-finalizer.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: test-grafana-cloud-onboarding-remove-alloy-and-finalizer
  namespace: test-namespace
  labels:
    app.kubernetes.io/name: test-grafana-cloud-onboarding-remove-alloy-and-finalizer
    app.kubernetes.io/instance: test
    helm.sh/chart: grafana-cloud-onboarding-0.4.0
  annotations:
    helm.sh/hook: pre-delete
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
spec:
  ttlSecondsAfterFinished: 300
  backoffLimit: 3
  template:
    metadata:
      name: test-grafana-cloud-onboarding-remove-alloy-and-finalizer
      labels:
        app.kubernetes.io/name: test-grafana-cloud-onboarding
        app.kubernetes.io/instance: test
        linkerd.io/inject: disabled
        sidecar.istio.io/inject: "false"
    spec:
      restartPolicy: Never
      nodeSelector:
        kubernetes.io/os: linux
      serviceAccountName: test-grafana-cloud-onboarding-remove-alloy-and-finalizer
      containers:
        - name: remove-finalizers
          image: "ghcr.io/grafana/helm-chart-toolbox-kubectl:0.1.1"
          imagePullPolicy: IfNotPresent
          command:
            - /bin/bash
            - -ce
            - |
              echo "Deleting Alloy instance: alloy/test-alloy-daemon..."
              kubectl delete alloy/test-alloy-daemon --ignore-not-found=true --wait
              kubectl wait --for=delete alloy/test-alloy-daemon --timeout=60s || echo "Timed out waiting for deletion of alloy/test-alloy-daemon or it may not exist."

              kubectl patch \
                --namespace=test-namespace \
                --type json \
                --patch='[{"op": "remove", "path": "/metadata/finalizers"}]' \
                deployment/test-alloy-operator
          securityContext:
            runAsNonRoot: true
            runAsUser: 4242
            allowPrivilegeEscalation: false
            capabilities:
              drop: ["ALL"]
            readOnlyRootFilesystem: true
            seccompProfile:
              type: RuntimeDefault
