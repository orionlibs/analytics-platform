# testing-with-grafana-cloud

Dreaming of using Grafana Cloud for all your testing needs? This repository will help you get started.

> Note: The demo app used for all examples is [QuickPizza](https://quickpizza.grafana.com/).

What you'll find here:
- `src/`
  - `backend/` – k6 tests for backend APIs
  - `web_app/` – k6 tests for frontend
  - `_lib/http_client.ts` – client autogenerated using [openapi-to-k6](https://github.com/grafana/openapi-to-k6)
  - `_studio/` – [k6 studio](https://grafana.com/docs/k6/latest/k6-studio/) artifacts
    - `data/` – reusable datasets (e.g. users.json)
    - `generators/` – test generators
    - `recordings/` – recordings of different user flows (HTTP)
- `specs/`
  - `quickpizza.openapi.yaml` – OpenAPI spec for QuickPizza
- `terraform/`
  - `gck6.projects.tf` – GCk6 projects, limits, and quotas
  - `gck6.permissions.tf` – GCk6 RBAC config (incl. [giving access to all projects to a specific team](https://github.com/dgzlopes/testing-with-grafana-cloud/blob/85f849f1054f6b99e0de615763e5dbf799ad4c3b/terraform/gck6.permissions.tf#L31))
  - `gck6.scheduled_tests.tf` – GCk6 scheduled tests
  - `sm.checks.tf` – Synthetic Monitoring checks (incl. [a multi-file scripted check](https://github.com/dgzlopes/testing-with-grafana-cloud/blob/02926a8f85e6d20d59430e499360279c1f3f4c22/terraform/sm.checks.tf#L23))
  - `stack.teams.tf` – Grafana Cloud stack teams and roles
- `k8s/`
  - `plz.definition.yaml` – GCk6 PLZ test definition
  - `plz.quota.yaml` – GCk6 PLZ quota config
- `.github/workflows/`
  - `ci.yaml` – runs on every push to main
     - spins up a local QuickPizza container
     - runs backend tests locally with [run-k6-action](https://github.com/grafana/run-k6-action)
     - annotates test runs with branch/PR metadata
  - `release.yaml` – runs on new GitHub Releases
     - runs backend tests in GCk6 with [run-k6-action](https://github.com/grafana/run-k6-action) (targeting a public QuickPizza deployment)
     - annotates runs with release metadata
     - sets the runs as baselines in GCk6
- `extensions/`
  - `Dockerfile` – Dockerfile to build a custom image with k6 extensions
  - `xk6-judge/` – custom k6 extension

## How to apply the Terraform resources to your Grafana Cloud stack

Make sure you have the following prerequisites installed:

- Node (>= 22.x)
- Terraform (>= 1.3.0)
- A Grafana Cloud account with an existing stack

After cloning the repository create a .env file based on the .env.example file.

```bash
cp .env.example .env
```

Then, edit the .env file and add a Grafana Cloud API Key and the details of your stack.
```
STACK_SLUG=mystack
CLOUD_REGION=prod-eu-west-2
CLOUD_ACCESS_POLICY_TOKEN=abdc123
```

That's it! Now run the following command to create the resources in your Grafana Cloud Stack.

```
make tf-bootstrap
```

Once you are done, you can check your Grafana Cloud stack to see the new resources.

If you want to clean up and remove all the resources created, just run:
```
make tf-destroy
```

**Where to find the Stack Slug and Cloud Region?**   
1. Log in to your Grafana Cloud account.
2. Select your organization from the organization drop-down menu.
3. In the Stacks section, click Details next to the stack you want to use.
4. Copy the Slug and the Region.

**How do I create a Grafana Cloud API key?**   
With a [Grafana Cloud Access Policy](https://grafana.com/docs/grafana-cloud/security-and-account-management/authentication-and-permissions/access-policies/). Make sure that you configure the minimun required scopes:  
- stacks:read   
- stacks:write   
- subscriptions:read   
- orgs:read   
- stack-service-accounts:write   	

## How to regenerate the client after updating the OpenAPI spec

Just run:

```
make gen-openapi-client
```

## How to work with k6 Studio artifacts

You can sync them between your local Studio installation and this repository using:
```bash
# Copy artifacts from the repo to your local Studio install
make studio-update-local

# Copy artifacts from your local Studio install to the repo
make studio-update-repo
```

Only generators, recordings and data files will be synced. 

The commands are non-destructive, meaning they will only add or update files, never delete them.
